{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End To End Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>35431.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15323.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BMW</td>\n",
       "      <td>Blue</td>\n",
       "      <td>192714.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19943.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>84714.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28343.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>White</td>\n",
       "      <td>154365.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>13434.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nissan</td>\n",
       "      <td>Blue</td>\n",
       "      <td>181577.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14043.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Make Colour  Odometer (KM)  Doors    Price\n",
       "0   Honda  White        35431.0    4.0  15323.0\n",
       "1     BMW   Blue       192714.0    5.0  19943.0\n",
       "2   Honda  White        84714.0    4.0  28343.0\n",
       "3  Toyota  White       154365.0    4.0  13434.0\n",
       "4  Nissan   Blue       181577.0    3.0  14043.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('..\\data\\car-sales-extended-missing-data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check data type and missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make              object\n",
      "Colour            object\n",
      "Odometer (KM)    float64\n",
      "Doors            float64\n",
      "Price            float64\n",
      "dtype: object\n",
      "Make             49\n",
      "Colour           50\n",
      "Odometer (KM)    50\n",
      "Doors            50\n",
      "Price            50\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.dtypes) \n",
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop Price(Lebels) 50 rows that missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make             47\n",
       "Colour           46\n",
       "Odometer (KM)    48\n",
       "Doors            47\n",
       "Price             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(subset=['Price'], axis=0, inplace=True)\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> some data have overlaping then some rows droped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we handle with missing value or scaling the data we must split to Train and Test set because **we dont' want estimators see the data before predict i.e. data leaked**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop('Price', axis=1)\n",
    "y = data['Price'].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scaling\n",
    "* Normalization (also called min-max scaling) - This rescales all the numerical values to between 0 and 1\n",
    "* Standardization - This subtracts the mean value from all of the features (so the resulting features have 0 mean)\n",
    "\n",
    "making sure all of your numerical data is on the same scale,  A machine learning algorithm may have trouble finding patterns in these wide-ranging variables.\n",
    "\n",
    "> Feature scaling usually isn't required for your target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling text and Categorical attributes\n",
    "convert from text to number ScikitLearn's OrdinalEncoder or OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\"\"\"\n",
    "fill missing cat_artribs with most_frequent \n",
    "num artrib with mean\n",
    "I want to change 'Make' column from OrdinalEncoder\n",
    "and other columns with OneHotEncoder\n",
    "and scaling numerical data\n",
    "\"\"\"\n",
    "\n",
    "make_artrib = ['Make']\n",
    "cat_artribs = ['Colour', 'Doors']\n",
    "num_artribs = ['Odometer (KM)']\n",
    "\n",
    "make_pipe = Pipeline([ \n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder',OrdinalEncoder())\n",
    "])\n",
    "\n",
    "cat_pipe = Pipeline([ \n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "num_pipe = Pipeline([ \n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', MinMaxScaler())\n",
    "])\n",
    "\n",
    "full_pipeline = ColumnTransformer([ \n",
    "    ('make_artribs',make_pipe,make_artrib),\n",
    "    ('cat_artribs',cat_pipe,cat_artribs),\n",
    "    ('num_artribs',num_pipe,num_artribs),\n",
    "], remainder='passthrough')\n",
    "\n",
    "X_train_transformed = full_pipeline.fit_transform(X_train)\n",
    "X_test_transformed = full_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Make</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Odometer (KM)</th>\n",
       "      <th>Doors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>Honda</td>\n",
       "      <td>White</td>\n",
       "      <td>71934.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>Toyota</td>\n",
       "      <td>Red</td>\n",
       "      <td>162665.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Make Colour  Odometer (KM)  Doors\n",
       "986   Honda  White        71934.0    4.0\n",
       "297  Toyota    Red       162665.0    4.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        1.        , 0.        , 1.        , 0.        , 0.25775097],\n",
       "       [3.        , 0.        , 0.        , 0.        , 1.        ,\n",
       "        0.        , 0.        , 1.        , 0.        , 0.636251  ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> alrigth we transform the data, **fit_transform** is we fit the scale from training set and transfrom that scale to testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 of training set = 0.8818\n",
      "R^2 of testing set = 0.2078\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rdf = RandomForestRegressor()\n",
    "rdf.fit(X_train_transformed, y_train)\n",
    "print('R^2 of training set = {:.4f}'.format(rdf.score(X_train_transformed, y_train)))\n",
    "print('R^2 of testing set = {:.4f}'.format(rdf.score(X_test_transformed, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> our model kinda overfitting : **overfit with training set and perform bad with testing set**\n",
    "\n",
    "> the score is R^2 (coefficient determination) on Regression model : with range -inf to 1.0 , if model predict the mean of the target score would be 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae of testing set = 5818.1002340152545\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "y_preds = rdf.predict(X_test_transformed)\n",
    "print('mae of testing set = {}'.format(mean_absolute_error(y_test, y_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5818.1002340152545"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(y_test - y_preds)) / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> mean_absolute_error : sum of | Ytrue - Ypred | / len(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6101.20436431 6060.62646583 6452.71631988 5169.95304393 6051.76696006]\n",
      "5967.253430801107\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "np.random.seed(42)\n",
    "rdf = RandomForestRegressor()\n",
    "score = cross_val_score(rdf, X_train_transformed, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
    "print(-score)\n",
    "print(np.mean(-score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *cross val score* : seperate data to n (cv=n) and train the others, ex. cv=5, 1st train 1-4 predict on 5, 2nd 2-5 predict on 1 ...., score is R^2 on regression and mean accurracy on classifier.\n",
    "\n",
    "> The fitting will be done inside the cross_val_score function, you don't need to worry about this beforehand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning\n",
    "* RandomizedSearchCV : Random hyperparams with n_iter estimators\n",
    "* GridSearchCV : fit all hyperparams that we set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {\n",
    "    'n_estimators':[10,50,100,150],\n",
    "    'max_depth':[None, 10,30],\n",
    "    'max_features':['auto', 'sqrt']\n",
    "}\n",
    "\n",
    "np.random.seed(42)\n",
    "clf = RandomForestRegressor(n_jobs=-1) # -1 = use all of CPU\n",
    "Rs_clf = RandomizedSearchCV(clf, params,n_iter=20, cv=5,verbose=0) # fit 20 hyparams with each 5 times\n",
    "Rs_clf.fit(X_train_transformed, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'n_estimators': 150, 'max_features': 'sqrt', 'max_depth': 10},\n",
       " 0.28835162740476894)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rs_clf.best_params_, Rs_clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get score or make prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18336812161358862"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rs_clf.score(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "np.random.seed(42)\n",
    "clf = RandomForestRegressor(n_jobs=-1)\n",
    "Gs_clf = GridSearchCV(clf,params,cv=5,verbose=0)\n",
    "Gs_clf.fit(X_train_transformed, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 10, 'max_features': 'sqrt', 'n_estimators': 50},\n",
       " 0.28819863533008794)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Gs_clf.best_params_, Gs_clf.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading models\n",
    "* pickle\n",
    "* joblib\n",
    "\n",
    "when handle with a large data **Joblib** is perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This RandomForestRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\alant\\Desktop\\Machine_Learning\\Machine_Learning_Journey\\sckit_learn--\\end-to-end.ipynb Cell 34'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alant/Desktop/Machine_Learning/Machine_Learning_Journey/sckit_learn--/end-to-end.ipynb#ch0000031?line=2'>3</a>\u001b[0m \u001b[39m# save model and pipeline\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alant/Desktop/Machine_Learning/Machine_Learning_Journey/sckit_learn--/end-to-end.ipynb#ch0000031?line=3'>4</a>\u001b[0m pickle\u001b[39m.\u001b[39mdump((rdf,full_pipeline), \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mmodel_1.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m)) \u001b[39m# write binary\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/alant/Desktop/Machine_Learning/Machine_Learning_Journey/sckit_learn--/end-to-end.ipynb#ch0000031?line=4'>5</a>\u001b[0m rdf\u001b[39m.\u001b[39;49mscore(X_test_transformed, y_test)\n",
      "File \u001b[1;32mc:\\Users\\alant\\Desktop\\Machine_Learning\\env\\lib\\site-packages\\sklearn\\base.py:705\u001b[0m, in \u001b[0;36mRegressorMixin.score\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/alant/Desktop/Machine_Learning/env/lib/site-packages/sklearn/base.py?line=662'>663</a>\u001b[0m \u001b[39m\"\"\"Return the coefficient of determination of the prediction.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/alant/Desktop/Machine_Learning/env/lib/site-packages/sklearn/base.py?line=663'>664</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/Users/alant/Desktop/Machine_Learning/env/lib/site-packages/sklearn/base.py?line=664'>665</a>\u001b[0m \u001b[39mThe coefficient of determination :math:`R^2` is defined as\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/alant/Desktop/Machine_Learning/env/lib/site-packages/sklearn/base.py?line=699'>700</a>\u001b[0m \u001b[39m:class:`~sklearn.multioutput.MultiOutputRegressor`).\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/alant/Desktop/Machine_Learning/env/lib/site-packages/sklearn/base.py?line=700'>701</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/alant/Desktop/Machine_Learning/env/lib/site-packages/sklearn/base.py?line=702'>703</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m r2_score\n\u001b[1;32m--> <a href='file:///c%3A/Users/alant/Desktop/Machine_Learning/env/lib/site-packages/sklearn/base.py?line=704'>705</a>\u001b[0m y_pred \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(X)\n\u001b[0;32m    <a href='file:///c%3A/Users/alant/Desktop/Machine_Learning/env/lib/site-packages/sklearn/base.py?line=705'>706</a>\u001b[0m \u001b[39mreturn\u001b[39;00m r2_score(y, y_pred, sample_weight\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[1;32mc:\\Users\\alant\\Desktop\\Machine_Learning\\env\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:969\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/alant/Desktop/Machine_Learning/env/lib/site-packages/sklearn/ensemble/_forest.py?line=949'>950</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    <a href='file:///c%3A/Users/alant/Desktop/Machine_Learning/env/lib/site-packages/sklearn/ensemble/_forest.py?line=950'>951</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/alant/Desktop/Machine_Learning/env/lib/site-packages/sklearn/ensemble/_forest.py?line=951'>952</a>\u001b[0m \u001b[39m    Predict regression target for X.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/alant/Desktop/Machine_Learning/env/lib/site-packages/sklearn/ensemble/_forest.py?line=952'>953</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/alant/Desktop/Machine_Learning/env/lib/site-packages/sklearn/ensemble/_forest.py?line=966'>967</a>\u001b[0m \u001b[39m        The predicted values.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/alant/Desktop/Machine_Learning/env/lib/site-packages/sklearn/ensemble/_forest.py?line=967'>968</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/alant/Desktop/Machine_Learning/env/lib/site-packages/sklearn/ensemble/_forest.py?line=968'>969</a>\u001b[0m     check_is_fitted(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    <a href='file:///c%3A/Users/alant/Desktop/Machine_Learning/env/lib/site-packages/sklearn/ensemble/_forest.py?line=969'>970</a>\u001b[0m     \u001b[39m# Check data\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/alant/Desktop/Machine_Learning/env/lib/site-packages/sklearn/ensemble/_forest.py?line=970'>971</a>\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_X_predict(X)\n",
      "File \u001b[1;32mc:\\Users\\alant\\Desktop\\Machine_Learning\\env\\lib\\site-packages\\sklearn\\utils\\validation.py:1222\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/alant/Desktop/Machine_Learning/env/lib/site-packages/sklearn/utils/validation.py?line=1216'>1217</a>\u001b[0m     fitted \u001b[39m=\u001b[39m [\n\u001b[0;32m   <a href='file:///c%3A/Users/alant/Desktop/Machine_Learning/env/lib/site-packages/sklearn/utils/validation.py?line=1217'>1218</a>\u001b[0m         v \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m \u001b[39mvars\u001b[39m(estimator) \u001b[39mif\u001b[39;00m v\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m_\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m v\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   <a href='file:///c%3A/Users/alant/Desktop/Machine_Learning/env/lib/site-packages/sklearn/utils/validation.py?line=1218'>1219</a>\u001b[0m     ]\n\u001b[0;32m   <a href='file:///c%3A/Users/alant/Desktop/Machine_Learning/env/lib/site-packages/sklearn/utils/validation.py?line=1220'>1221</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fitted:\n\u001b[1;32m-> <a href='file:///c%3A/Users/alant/Desktop/Machine_Learning/env/lib/site-packages/sklearn/utils/validation.py?line=1221'>1222</a>\u001b[0m     \u001b[39mraise\u001b[39;00m NotFittedError(msg \u001b[39m%\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mtype\u001b[39m(estimator)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This RandomForestRegressor instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# save model and pipeline\n",
    "pickle.dump((rdf,full_pipeline), open('model_1.pkl', 'wb')) # write binary\n",
    "rdf.score(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19986344207016027"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model = pickle.load(open('model_1.pkl', 'rb')) # read binary\n",
    "loaded_model[0].score(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Make              Toyota\n",
       "Colour              Blue\n",
       "Odometer (KM)    99761.0\n",
       "Doors                4.0\n",
       "Name: 203, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 1.        , 0.        , 0.78225537])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 1.        , 0.        , 0.78225537])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model[1].transform(X_test)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_1.joblib']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "dump((rdf, full_pipeline),'model_1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19986344207016027"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model_2 = load('model_1.joblib')\n",
    "loaded_model_2[0].score(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 1.        , 0.        , 0.78225537])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model_2[1].transform(X_test)[2]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b572caadb8bd68b0a5f9ddee202b3becd15d80e56a230202715712ddf00ae820"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
